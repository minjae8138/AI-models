{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO/tRI2dRW4xcA4AvcSfaEN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b66f85309cb249fe9e0de86771cb0bc5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_454f4a88ac524572a553df9a1765d85d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_428e665508d24accb896a62afc2e5d28","IPY_MODEL_17e38c9b141e4d60bec52e4f8c3f550d"]}},"454f4a88ac524572a553df9a1765d85d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"428e665508d24accb896a62afc2e5d28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_84bd4f8413db436d81a8941c53c0c86b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":69,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":69,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_033d737baf4540b3a090fa7e19a10aa8"}},"17e38c9b141e4d60bec52e4f8c3f550d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_32b38250d30249dabf3e3764e7338983","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 69/69 [00:00&lt;00:00, 157.61it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a735b4bfa3642c08c090cf4a5a8f7f8"}},"84bd4f8413db436d81a8941c53c0c86b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"033d737baf4540b3a090fa7e19a10aa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32b38250d30249dabf3e3764e7338983":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7a735b4bfa3642c08c090cf4a5a8f7f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"039041d1d74f41d0b1f6bf2e23d99429":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_97cfce4abf55483a88d9ea1844d7b80d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7cb3c2132cf5414a9058e19d19b85762","IPY_MODEL_e0787c1432104460814ddd01282a3114"]}},"97cfce4abf55483a88d9ea1844d7b80d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cb3c2132cf5414a9058e19d19b85762":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d4931a0065864bb0a6b98750725d4777","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":20,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":20,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b82e8534a7724636b7932b6e2fe88d8a"}},"e0787c1432104460814ddd01282a3114":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_260d97d2f1b248fdbbddc89b9cf6a958","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 20/20 [00:00&lt;00:00, 130.48it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b2a912e532d4a9e809dc50d6256ddff"}},"d4931a0065864bb0a6b98750725d4777":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b82e8534a7724636b7932b6e2fe88d8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"260d97d2f1b248fdbbddc89b9cf6a958":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8b2a912e532d4a9e809dc50d6256ddff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"1tyElhXCoC1y","executionInfo":{"status":"ok","timestamp":1627019270409,"user_tz":-540,"elapsed":37057,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"cd9d28c2-a350-45b6-e104-bcd790030aac"},"source":["!pip install -r requirements.txt\n","# !pip install git+https://github.com/PyTorchLightning/pytorch-lightning\n","!pip install kobart-transformers\n","!pip install nlp"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.1.5)\n","Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.9.0+cu102)\n","Collecting transformers==4.3.3\n","  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 26.7 MB/s \n","\u001b[?25hCollecting streamlit==0.72.0\n","  Downloading streamlit-0.72.0-py2.py3-none-any.whl (7.4 MB)\n","\u001b[K     |████████████████████████████████| 7.4 MB 31.9 MB/s \n","\u001b[?25hCollecting pytorch-lightning\n","  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\n","\u001b[K     |████████████████████████████████| 813 kB 55.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->-r requirements.txt (line 2)) (3.7.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 3)) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 3)) (3.0.12)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 41.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 3)) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 3)) (21.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 3)) (4.6.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 57.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r requirements.txt (line 3)) (2019.12.20)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (0.10.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (2.8.1)\n","Collecting watchdog\n","  Downloading watchdog-2.1.3-py3-none-manylinux2014_x86_64.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 4.0 MB/s \n","\u001b[?25hCollecting base58\n","  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (3.0.0)\n","Collecting pydeck>=0.1.dev5\n","  Downloading pydeck-0.6.2-py2.py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 60.6 MB/s \n","\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (4.1.0)\n","Collecting gitpython\n","  Downloading GitPython-3.1.19-py3-none-any.whl (177 kB)\n","\u001b[K     |████████████████████████████████| 177 kB 63.8 MB/s \n","\u001b[?25hRequirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (0.8.1)\n","Collecting validators\n","  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (3.17.3)\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (5.1.1)\n","Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (4.2.2)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit==0.72.0->-r requirements.txt (line 4)) (1.5.1)\n","Collecting blinker\n","  Downloading blinker-1.4.tar.gz (111 kB)\n","\u001b[K     |████████████████████████████████| 111 kB 60.7 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2018.9)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.72.0->-r requirements.txt (line 4)) (0.3)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.72.0->-r requirements.txt (line 4)) (2.6.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.72.0->-r requirements.txt (line 4)) (0.11.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.72.0->-r requirements.txt (line 4)) (2.11.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit==0.72.0->-r requirements.txt (line 4)) (1.15.0)\n","Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (5.0.5)\n","Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (7.6.3)\n","Collecting ipykernel>=5.1.2\n","  Downloading ipykernel-6.0.3-py3-none-any.whl (122 kB)\n","\u001b[K     |████████████████████████████████| 122 kB 59.1 MB/s \n","\u001b[?25hRequirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (1.0.0)\n","Collecting ipython<8.0,>=7.23.1\n","  Downloading ipython-7.25.0-py3-none-any.whl (786 kB)\n","\u001b[K     |████████████████████████████████| 786 kB 62.7 MB/s \n","\u001b[?25hRequirement already satisfied: jupyter-client<7.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (5.3.5)\n","Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.1.2)\n","Collecting importlib-metadata\n","  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3->-r requirements.txt (line 3)) (3.5.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (4.4.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.18.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.2.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (57.2.0)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.19-py3-none-any.whl (368 kB)\n","\u001b[K     |████████████████████████████████| 368 kB 63.4 MB/s \n","\u001b[?25hRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (2.6.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (1.0.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (5.1.3)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (3.5.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.8.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit==0.72.0->-r requirements.txt (line 4)) (2.0.1)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (4.7.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (22.1.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (5.3.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (5.6.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.10.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (1.7.1)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 64.1 MB/s \n","\u001b[?25hCollecting PyYAML<=5.4.1,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 62.7 MB/s \n","\u001b[?25hCollecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 53.9 MB/s \n","\u001b[?25hCollecting torchmetrics>=0.2.0\n","  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 55.8 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.0\n","  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n","Collecting tensorboard!=2.5.0,>=2.2.0\n","  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n","\u001b[K     |████████████████████████████████| 10.6 MB 46.2 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 49.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->-r requirements.txt (line 3)) (2.4.7)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (1.32.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (1.8.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (1.34.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (0.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (0.36.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (3.3.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (0.4.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 3)) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning->-r requirements.txt (line 5)) (3.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r requirements.txt (line 5)) (21.2.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 63.4 MB/s \n","\u001b[?25hCollecting async-timeout<4.0,>=3.0\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 60.8 MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25hCollecting smmap<5,>=3.0.1\n","  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (3.3.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (1.4.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.7.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.5.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.8.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.72.0->-r requirements.txt (line 4)) (0.5.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->-r requirements.txt (line 3)) (1.0.1)\n","Building wheels for collected packages: future, blinker\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=a40a94943e4a129d50e735f054b19a91fbc62a0a5065194d991fcc4924566df9\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13479 sha256=a6c725bd5e9738aa157f0621b4a5f0adc5c35c1e102a34c5263f78835efe1691\n","  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n","Successfully built future blinker\n","Installing collected packages: prompt-toolkit, ipython, importlib-metadata, ipykernel, multidict, yarl, smmap, async-timeout, gitdb, fsspec, aiohttp, watchdog, validators, torchmetrics, tokenizers, tensorboard, sacremoses, PyYAML, pyDeprecate, pydeck, gitpython, future, blinker, base58, transformers, streamlit, pytorch-lightning\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.6.1\n","    Uninstalling importlib-metadata-4.6.1:\n","      Successfully uninstalled importlib-metadata-4.6.1\n","  Attempting uninstall: ipykernel\n","    Found existing installation: ipykernel 4.10.1\n","    Uninstalling ipykernel-4.10.1:\n","      Successfully uninstalled ipykernel-4.10.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.19 which is incompatible.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.0.3 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.25.0 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 base58-2.1.0 blinker-1.4 fsspec-2021.7.0 future-0.18.2 gitdb-4.0.7 gitpython-3.1.19 importlib-metadata-3.10.1 ipykernel-6.0.3 ipython-7.25.0 multidict-5.1.0 prompt-toolkit-3.0.19 pyDeprecate-0.3.0 pydeck-0.6.2 pytorch-lightning-1.3.8 sacremoses-0.0.45 smmap-4.0.0 streamlit-0.72.0 tensorboard-2.4.1 tokenizers-0.10.3 torchmetrics-0.4.1 transformers-4.3.3 validators-0.18.2 watchdog-2.1.3 yarl-1.6.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","ipykernel","prompt_toolkit"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting kobart-transformers\n","  Downloading kobart_transformers-0.1.4-py3-none-any.whl (3.3 kB)\n","Installing collected packages: kobart-transformers\n","Successfully installed kobart-transformers-0.1.4\n","Collecting nlp\n","  Downloading nlp-0.4.0-py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 36.6 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 49.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nlp) (3.0.12)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from nlp) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlp) (1.1.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from nlp) (0.3.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlp) (1.19.5)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlp) (3.0.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from nlp) (4.41.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.15.0)\n","Installing collected packages: xxhash, nlp\n","Successfully installed nlp-0.4.0 xxhash-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3A72i7i9oTFU"},"source":["# imports\n","import transformers\n","from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n","import pandas as pd\n","import numpy as np\n","\n","import torch.nn.functional as F\n","import pytorch_lightning as pl\n","import torch\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","import math\n","import random\n","import re\n","import argparse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15DdnatWsDCQ","executionInfo":{"status":"ok","timestamp":1627023255311,"user_tz":-540,"elapsed":8155,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"28b5c57e-b2d3-4d27-90e3-1675fd42fb62"},"source":["from transformers import (\n","    Seq2SeqTrainer,\n","    Seq2SeqTrainingArguments,\n","    AutoTokenizer,\n","    AutoModelForSeq2SeqLM,\n","    Trainer,\n","    TrainingArguments,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-23 06:54:10.544128: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"FRWbD7O7BZOl"},"source":["# 모델, 토크나이저 정의"]},{"cell_type":"code","metadata":{"id":"s_zr_l7Zu0pF"},"source":["from kobart_transformers import get_kobart_model, get_kobart_tokenizer\n","from transformers import PreTrainedTokenizerFast\n","from transformers import BartForSequenceClassification\n","# tokenizer = get_kobart_tokenizer()\n","# model = get_kobart_model()\n","tokenizer = AutoTokenizer.from_pretrained(\"hyunwoongko/kobart\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"hyunwoongko/kobart\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFNQpCWgPJEC","executionInfo":{"status":"ok","timestamp":1627023282881,"user_tz":-540,"elapsed":256,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"2316d14d-995d-49e6-e968-54ef7f24f084"},"source":["tokenizer([\"한국어\", \"모델을\", \"소개합니다.\"], truncation=True, padding=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[15274, 11763, 3], [18181, 12007, 3], [11319, 9006, 20357]], 'attention_mask': [[1, 1, 0], [1, 1, 0], [1, 1, 1]]}"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"A93gpRTwBKEE"},"source":["# 데이터 로드 및 병합"]},{"cell_type":"code","metadata":{"id":"iOFqQWXH7wp4"},"source":["import nlp\n","data = pd.read_excel(\"bonobono.xlsx\")\n","dataset = data.iloc[:,2:4]\n","dataset = dataset.dropna(axis=0,how='any')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s9xmM7_H6DEA"},"source":["data1 = pd.read_excel(\"sea1.xlsx\")\n","dataset1 = data1.iloc[:,2:4]\n","dataset1 = dataset1.dropna(axis=0,how='any')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ColZmVrC7qWL"},"source":["data2 = pd.read_excel(\"sea2.xlsx\")\n","dataset2 = data2.iloc[:,2:4]\n","dataset2 = dataset2.dropna(axis=0,how='any')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uco2dBKJ9qFO"},"source":["# data3 = pd.read_excel(\"chatbot.xlsx\")\n","# dataset3 = data3.iloc[:,1:3]\n","# dataset3 = dataset3.dropna(axis=0,how='any')\n","\n","# 데이터 이상치가 많음"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewUJRXJw91Mc"},"source":["dataset = dataset.append((dataset1,dataset2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kE_SKDFX7Prg","executionInfo":{"status":"ok","timestamp":1627023300204,"user_tz":-540,"elapsed":253,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"af688901-5d7a-4f88-c41c-57e964e3f498"},"source":["dataset.info()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1405 entries, 0 to 443\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   반말A     1405 non-null   object\n"," 1   존댓말A    1405 non-null   object\n","dtypes: object(2)\n","memory usage: 32.9+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UTxlFit2_vbk"},"source":["train_dataset = nlp.Dataset.from_pandas(dataset[:1100])\n","val_dataset = nlp.Dataset.from_pandas(dataset[1100:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHQz8JJY_Q8q","executionInfo":{"status":"ok","timestamp":1627023323225,"user_tz":-540,"elapsed":6,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"a195ffa4-7d39-4b9f-a697-c81f91afd97f"},"source":["train_dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset(features: {'반말A': Value(dtype='string', id=None), '존댓말A': Value(dtype='string', id=None), '__index_level_0__': Value(dtype='int64', id=None)}, num_rows: 1100)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"b4xpKloy744O"},"source":["def map_to_encoder_decoder_inputs(batch):\n","    inputs = tokenizer(batch[\"반말A\"], padding=\"max_length\", truncation=True, max_length=40) # 반말\n","    outputs = tokenizer(batch[\"존댓말A\"], padding=\"max_length\", truncation=True, max_length=40) # 존댓말\n","\n","    batch[\"input_ids\"] = inputs.input_ids\n","    batch[\"attention_mask\"] = inputs.attention_mask\n","\n","    # batch[\"decoder_input_ids\"] = outputs.input_ids\n","    batch[\"labels\"] = outputs.input_ids\n","    # batch[\"labels\"] = [\n","    #     [-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]\n","    # ]\n","    # model.generate(inputs.input_ids)\n","    # batch[\"decoder_attention_mask\"] = outputs.attention_mask\n","    \n","    # print(\"inputs:\",inputs)\n","    # print(\"outputs:\",outputs)\n","    assert all([len(x) == 40 for x in inputs.input_ids])\n","    assert all([len(x) == 40 for x in outputs.input_ids])\n","\n","    return batch\n","\n","def compute_metrics(pred):\n","    labels_ids = pred.label_ids\n","    pred_ids = pred.predictions\n","\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n","\n","    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n","\n","    return {\n","      \"rouge2_precision\": round(rouge_output.precision, 4),\n","      \"rouge2_recall\": round(rouge_output.recall, 4),\n","      \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119,"referenced_widgets":["b66f85309cb249fe9e0de86771cb0bc5","454f4a88ac524572a553df9a1765d85d","428e665508d24accb896a62afc2e5d28","17e38c9b141e4d60bec52e4f8c3f550d","84bd4f8413db436d81a8941c53c0c86b","033d737baf4540b3a090fa7e19a10aa8","32b38250d30249dabf3e3764e7338983","7a735b4bfa3642c08c090cf4a5a8f7f8","039041d1d74f41d0b1f6bf2e23d99429","97cfce4abf55483a88d9ea1844d7b80d","7cb3c2132cf5414a9058e19d19b85762","e0787c1432104460814ddd01282a3114","d4931a0065864bb0a6b98750725d4777","b82e8534a7724636b7932b6e2fe88d8a","260d97d2f1b248fdbbddc89b9cf6a958","8b2a912e532d4a9e809dc50d6256ddff"]},"id":"tQLPdqT5746o","executionInfo":{"status":"ok","timestamp":1627023329730,"user_tz":-540,"elapsed":646,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"fcb37827-786d-4294-c484-a2677f43728b"},"source":["batch_size = 16\n","\n","train_dataset = train_dataset.map(\n","    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[\"반말A\", \"존댓말A\"],\n",")\n","train_dataset.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"attention_mask\",\"labels\"],\n",")\n","\n","val_dataset = val_dataset.map(\n","    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[\"반말A\", \"존댓말A\"],\n",")\n","val_dataset.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"attention_mask\",\"labels\"],\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b66f85309cb249fe9e0de86771cb0bc5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=69.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"039041d1d74f41d0b1f6bf2e23d99429","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I__SOnhXju2c","executionInfo":{"status":"ok","timestamp":1627023345088,"user_tz":-540,"elapsed":12280,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"418ea920-9db9-45e2-ffba-9e1b4480966e"},"source":["model.to('cuda')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768, padding_idx=3)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768, padding_idx=3)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"NDu6A9Uahyxo"},"source":["# !nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6Vfa3RkRvCQ","executionInfo":{"status":"ok","timestamp":1627023372976,"user_tz":-540,"elapsed":9,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"7c11b051-4f62-426c-9477-19c75a358796"},"source":["train_dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset(features: {'__index_level_0__': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 1100)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"cZZ0MoTm749E"},"source":["base_dir = 'content/'\n","# checkpoint = ModelCheckpoint(filepath=base_dir + 'checkpoint_files_1/')\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./\",\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    # evaluate_during_training=True,\n","    do_train=True,\n","    # do_eval=True,\n","    logging_steps=5,\n","#     save_steps=5,\n","    eval_steps=20,\n","    overwrite_output_dir=True,\n","    warmup_steps=100,\n","    save_total_limit=1,\n","    num_train_epochs=5,\n","    # checkpoint_callback = checkpoint,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n",")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xIJ-1pE-74_e","executionInfo":{"status":"ok","timestamp":1627023453831,"user_tz":-540,"elapsed":75252,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"8cd12e67-e1d2-469c-cb32-c85ec4345879"},"source":["trainer.train()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='345' max='345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [345/345 01:14, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>5</td>\n","      <td>17.305600</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>15.046900</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>13.323900</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>10.517600</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>9.116300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>7.501200</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>5.836200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>4.461800</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>3.911000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>3.331900</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>3.001000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.516700</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>2.173600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>1.674700</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>1.314400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.031200</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.736900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.626200</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.440800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.533600</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>0.419000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.501400</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>0.442200</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.428900</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.381800</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.456600</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>0.485400</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.291200</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>0.251800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.273200</td>\n","    </tr>\n","    <tr>\n","      <td>155</td>\n","      <td>0.265200</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.269900</td>\n","    </tr>\n","    <tr>\n","      <td>165</td>\n","      <td>0.234100</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.201400</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.263200</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.248800</td>\n","    </tr>\n","    <tr>\n","      <td>185</td>\n","      <td>0.256500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.286600</td>\n","    </tr>\n","    <tr>\n","      <td>195</td>\n","      <td>0.293800</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.308100</td>\n","    </tr>\n","    <tr>\n","      <td>205</td>\n","      <td>0.249000</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.205500</td>\n","    </tr>\n","    <tr>\n","      <td>215</td>\n","      <td>0.141100</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.126500</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>0.135800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.179700</td>\n","    </tr>\n","    <tr>\n","      <td>235</td>\n","      <td>0.144000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.120700</td>\n","    </tr>\n","    <tr>\n","      <td>245</td>\n","      <td>0.128000</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.157400</td>\n","    </tr>\n","    <tr>\n","      <td>255</td>\n","      <td>0.149000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.159600</td>\n","    </tr>\n","    <tr>\n","      <td>265</td>\n","      <td>0.144900</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.113800</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>0.185500</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.102100</td>\n","    </tr>\n","    <tr>\n","      <td>285</td>\n","      <td>0.109800</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.091700</td>\n","    </tr>\n","    <tr>\n","      <td>295</td>\n","      <td>0.094500</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.108800</td>\n","    </tr>\n","    <tr>\n","      <td>305</td>\n","      <td>0.096900</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.114600</td>\n","    </tr>\n","    <tr>\n","      <td>315</td>\n","      <td>0.077900</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.102500</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>0.107000</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.086800</td>\n","    </tr>\n","    <tr>\n","      <td>335</td>\n","      <td>0.081200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.089600</td>\n","    </tr>\n","    <tr>\n","      <td>345</td>\n","      <td>0.121100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=345, training_loss=1.6621123881443687, metrics={'train_runtime': 75.1108, 'train_samples_per_second': 4.593, 'total_flos': 163495157760000, 'epoch': 5.0})"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"sYT2AxgP75Bq","executionInfo":{"status":"ok","timestamp":1627023499686,"user_tz":-540,"elapsed":1515,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"3c824eba-5807-4010-b36e-87210032ca68"},"source":["inputs = tokenizer.encode(\"오늘 날씨 짱 좋아!!!\", return_tensors='pt')\n","model.to('cpu')\n","pred = model.generate(inputs)\n","tokenizer.decode(pred[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<usr>오늘 날씨 날씨 짱 좋아요<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"_1X6EaxtBamp"},"source":["torch.save(model.state_dict(), 'kobart')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2y9dPskBrNd","executionInfo":{"status":"ok","timestamp":1627023526599,"user_tz":-540,"elapsed":615,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"6029604c-c5ba-4903-a435-d54989659a3c"},"source":["model.load_state_dict(torch.load('kobart'))\n","model.eval()\n","type(model)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["transformers.models.bart.modeling_bart.BartForConditionalGeneration"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"-cSU5erVfJh4"},"source":["class Styleformer():\n","\n","    def __init__(self,  style=0):\n","        from transformers import AutoTokenizer\n","        from transformers import AutoModelForSeq2SeqLM\n","#         from styleformer import Adequacy\n","\n","        self.style = style\n","        self.adequacy = Adequacy()\n","        self.model_loaded = False\n","\n","        if self.style == 0:\n","            self.ctf_tokenizer = AutoTokenizer.from_pretrained(\"hyunwoongko/kobart\")\n","            model.load_state_dict(torch.load('content'))\n","            self.ctf_model = model\n","#             print(\"test->\",self.ctf_tokenizer(\"today is a sunny day\"))\n","            \n","            print(\"Casual to Formal model loaded...\")\n","            self.model_loaded = True\n","        else:\n","            print(\"Only CTF, FTC, ATP and PTA are supported in the pre-release...stay tuned\")\n","\n","    def transfer(self, input_sentence, inference_on=0, quality_filter=0.95, max_candidates=5):\n","        if self.model_loaded:\n","            if inference_on == 0:\n","                device = \"cpu\"\n","            elif inference_on == 1:\n","                device = \"cuda:0\"  \n","            else:  \n","                device = \"cpu\"\n","                print(\"Onnx + Quantisation is not supported in the pre-release...stay tuned.\")\n","\n","            if self.style == 0:\n","                output_sentence = self._casual_to_formal(input_sentence, device, quality_filter, max_candidates)\n","                return output_sentence     \n","        else:\n","            print(\"Models aren't loaded for this style, please use the right style during init\")  \n","\n","\n","    def _casual_to_formal(self, input_sentence, device, quality_filter, max_candidates):\n","        ctf_prefix = \"transfer Casual to Formal: \"\n","        src_sentence = input_sentence\n","        input_sentence = ctf_prefix + input_sentence\n","        input_ids = self.ctf_tokenizer.encode(input_sentence, return_tensors='pt')\n","        self.ctf_model = self.ctf_model.to(device)\n","        input_ids = input_ids.to(device)\n","\n","        \n","        preds = self.ctf_model.generate(\n","            input_ids,\n","            do_sample=True, \n","            max_length=32, \n","            top_k=50, \n","            top_p=0.95, \n","            early_stopping=True,\n","            num_return_sequences=max_candidates)\n","        print(\"preds : \",preds)\n","        gen_sentences = set()\n","        for pred in preds:\n","            gen_sentences.add(self.ctf_tokenizer.decode(pred, skip_special_tokens=True).strip())\n","        print(\"gensentences\",gen_sentences)\n","        adequacy_scored_phrases = self.adequacy.score(src_sentence, list(gen_sentences), quality_filter, device)\n","        ranked_sentences = sorted(adequacy_scored_phrases.items(), key = lambda x:x[1], reverse=True)\n","        print(adequacy_scored_phrases)\n","        print(\"ranked\",ranked_sentences)\n","        if len(ranked_sentences) > 0:\n","            return ranked_sentences[0][0]\n","        else:\n","            return None\n","\n","\n","     \n","        return self.pta_tokenizer.decode(preds[0], skip_special_tokens=True).strip()      \n","\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JxoeFIo075D7"},"source":["class Adequacy():\n","\n","  def __init__(self, model_tag='prithivida/parrot_adequacy_on_BART'):\n","    from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","    from transformers import PreTrainedTokenizerFast\n","    # self.nli_model = BartModel.from_pretrained(model_tag)\n","    # self.tokenizer = PreTrainedTokenizerFast.from_pretrained(model_tag)\n","    \n","    self.nli_model = AutoModelForSequenceClassification.from_pretrained(model_tag)\n","    self.tokenizer = AutoTokenizer.from_pretrained(model_tag)\n","    \n","  def filter(self, input_phrase, para_phrases, adequacy_threshold, device=\"cpu\"):\n","      top_adequacy_phrases = []\n","      for para_phrase in para_phrases:\n","        x = self.tokenizer.encode(input_phrase, para_phrase, return_tensors='pt',truncation_strategy='only_first')\n","        self.nli_model = self.nli_model.to(device)\n","        logits = self.nli_model(x.to(device))[0]\n","        # we throw away \"neutral\" (dim 1) and take the probability of \"entailment\" (2) as the adequacy score\n","        entail_contradiction_logits = logits[:,[0,2]]\n","        probs = entail_contradiction_logits.softmax(dim=1)\n","        prob_label_is_true = probs[:,1]\n","        adequacy_score = prob_label_is_true[0].item()\n","        if adequacy_score >= adequacy_threshold:\n","            top_adequacy_phrases.append(para_phrase)\n","      return top_adequacy_phrases\n","\n","  def score(self, input_phrase, para_phrases, adequacy_threshold, device=\"cpu\"):\n","      adequacy_scores = {}\n","      for para_phrase in para_phrases:\n","        x = self.tokenizer.encode(input_phrase, para_phrase, return_tensors='pt',truncation_strategy='only_first')\n","        self.nli_model = self.nli_model.to(device)\n","        logits = self.nli_model(x.to(device))[0]\n","        # we throw away \"neutral\" (dim 1) and take the probability of \"entailment\" (2) as the adequacy score\n","        entail_contradiction_logits = logits[:,[0,2]]\n","        probs = entail_contradiction_logits.softmax(dim=1)\n","#         print(\"logits-----\",logits)\n","#         print(\"entail\",entail_contradiction_logits)\n","#         print(\"probs\",probs)\n","        prob_label_is_true = probs[:,1]\n","        print(\"prob_label_is_true : \",prob_label_is_true )\n","        adequacy_score = prob_label_is_true[0].item()\n","        if adequacy_score >= adequacy_threshold:\n","          adequacy_scores[para_phrase] = adequacy_score\n","#         print(adequacy_scores)\n","      return adequacy_scores      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"isVlSjuTdfig","executionInfo":{"status":"ok","timestamp":1627023659220,"user_tz":-540,"elapsed":105424,"user":{"displayName":"min jae kim","photoUrl":"","userId":"00605794776296592837"}},"outputId":"655c4211-c33c-408f-b44b-1fd0506771ad"},"source":["# from styleformer import Styleformer\n","import torch\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","'''\n","#uncomment for re-producability\n","def set_seed(seed):\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","set_seed(1234)\n","'''\n","\n","# style = [0=Casual to Formal, 1=Formal to Casual, 2=Active to Passive, 3=Passive to Active etc..]\n","sf = Styleformer(style = 0)\n","\n","source_sentences = [\n","\"안녕, 나는 파새라고 해\",\n","\"그야 있었겠지, 너도 동의하지?\",\n","\"응, 맞아. 다들 참기만 해.\",\n","\n","]\n","\n","for source_sentence in source_sentences:\n","    target_sentence = sf.transfer(source_sentence)\n","    print(\"-\" *100)\n","    print(\"[Casual] \", source_sentence)\n","    print(\"-\" *100)\n","    if target_sentence is not None:\n","        print(\"[Formal] \",target_sentence)\n","        print()\n","    else:\n","        print(\"No good quality transfers available !\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at prithivida/parrot_adequacy_on_BART were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n","- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["Casual to Formal model loaded...\n","preds :  tensor([[    2,   315,   313, 15195,   314,   301, 14879, 14664, 16884, 19512,\n","         21235, 15418, 21738, 17510, 21579, 26545, 15585,   257,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19783, 23795,\n","           315, 21579, 15418, 15463,   308, 15585,   257, 22465,   243, 16530,\n","         14240, 11229, 14218, 14088, 14543,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19542,   316,\n","         15585, 27141, 15418, 15463,   308, 15585,   257, 22465,   243, 16530,\n","         14240, 11229, 14218, 14088, 14543,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19783,   313,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19783,   313,\n","         26605, 27141, 15418, 15463,   308, 15585,   257, 22465,   243, 16530,\n","         14240, 11229, 14218, 14088, 14543,     3,     3,     3,     3,     3,\n","             3,     3]])\n","gensentences {'transfer Contr', 'transfer Context for Formal: 안녕, 저는 파새라고 해요.', 'transfer Centur the First forestal:', 'transfer Contrace to Formal: 안녕, 저는 파새라고 해요.', 'transfer Casual to Formal: 안녕, 저는 파새라고 해요.'}\n","prob_label_is_true :  tensor([0.6463], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.9180], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.0748], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.4703], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.8770], grad_fn=<SelectBackward>)\n","{}\n","ranked []\n","----------------------------------------------------------------------------------------------------\n","[Casual]  안녕, 나는 파새라고 해\n","----------------------------------------------------------------------------------------------------\n","No good quality transfers available !\n","preds :  tensor([[    2,   315,   313, 15195,   314,   301, 14879, 14664, 19542,   316,\n","         15585, 27141, 15418, 15463,   308, 15585,   257, 14028, 11734, 14418,\n","          9060, 12244,   262,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19542,   316,\n","         15585, 27141, 15418, 15463,   308, 15585,   257, 14028, 11734, 14418,\n","          9060, 12244,   262,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19542,   316,\n","         15585, 27141, 15418, 15463,   308, 15585,   257, 14028, 11734, 14418,\n","          9060, 12244,   243,  1700,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 27580,   316,\n","         15585, 27141, 15418, 15463,   308, 15585,   257, 14028, 11734, 14418,\n","          9060, 12244,   243, 14038, 21412, 17719, 14242, 17784,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 16884, 21579,\n","         15418, 15463,   308, 15585,   257, 14028, 11734, 14418,  9060, 12244,\n","           243,  1700,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3]])\n","gensentences {'transfer Casual to Formal: 그야 있었겠죠?', 'transfer Cent for Formal: 그야 있었겠죠,', 'transfer Casual to Formal: 그야 있었겠죠,', 'transfer Classual to Formal: 그야 있었겠죠, 전 저도 동의하지요?'}\n","prob_label_is_true :  tensor([0.8803], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.6829], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.8630], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.8871], grad_fn=<SelectBackward>)\n","{}\n","ranked []\n","----------------------------------------------------------------------------------------------------\n","[Casual]  그야 있었겠지, 너도 동의하지?\n","----------------------------------------------------------------------------------------------------\n","No good quality transfers available !\n","preds :  tensor([[    2,   315,   313, 15195,   314,   301, 14879, 14664, 19542,   316,\n","         15585, 27141, 15418, 15463,   308, 15585,  1700,     3,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 16884, 19512,\n","         15585, 27141, 15418, 15463,   308, 15585,   257, 19102, 11696, 14543,\n","         26852, 14214, 20302, 14042, 17984,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19542,   316,\n","         15585, 27141, 15418, 15463,   308, 15585, 12005, 14292,  9567, 14543,\n","         26852, 14214, 20302, 14042, 17984,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 16884,   313,\n","         15585, 27141, 15418, 15463,   308, 15585,   257, 17508, 14214, 20302,\n","         14042, 17984,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19783,   316,\n","         15585, 27141, 15418, 15463,   308, 15585,   257,  1700,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3]])\n","gensentences {'transfer Casual to Formal은 맞네요. 다들 참기만 하죠.', 'transfer Contual to Formal:', 'transfer Casual to Formal', 'transfer Centural to Formal: 괜찮아요. 다들 참기만 하죠.', 'transfer Central to Formal: 굉장히 참기만 하죠.'}\n","prob_label_is_true :  tensor([0.1349], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.4020], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.3046], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.0771], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.1118], grad_fn=<SelectBackward>)\n","{}\n","ranked []\n","----------------------------------------------------------------------------------------------------\n","[Casual]  응, 맞아. 다들 참기만 해.\n","----------------------------------------------------------------------------------------------------\n","No good quality transfers available !\n","preds :  tensor([[    2, 16042, 15109, 15061, 22018, 14049, 14205, 24612,  9286, 17784,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313,  9747, 12007, 15384, 17355,  9567, 14543,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 16203,   301, 14879, 14664, 16884, 14879, 21579,\n","         15418, 21738, 17510, 25614, 26545, 15585,   314, 21579, 26545, 20775,\n","         16203,   243, 27842,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19783, 26545,\n","         15585, 27141, 15418, 15463, 26545, 15585, 25614, 20924, 18509,   257,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 16884, 25614, 26997,   314, 21579, 26545, 21579,\n","         15418,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3]])\n","gensentences {'trent ranks forest for F', '하지만 그렇게스로페이스하는 건 어떨까요?', 'transfer Contestal to Forestal rapid:', 'trlefer Center for First restals forestable, y', 'tr닝을 하면 좋겠네요.'}\n","prob_label_is_true :  tensor([0.0164], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.2171], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.0226], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.0054], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.2678], grad_fn=<SelectBackward>)\n","{}\n","ranked []\n","----------------------------------------------------------------------------------------------------\n","[Casual]  I am quitting my job\n","----------------------------------------------------------------------------------------------------\n","No good quality transfers available !\n","preds :  tensor([[    2,   315,   313, 15195,   314,   316, 15585, 17254, 27818, 17254,\n","         27818,   314, 14543,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2, 23579, 11900, 15165, 14047, 17512, 14215, 17275,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2, 15943,  1700, 12002, 10290, 26496, 16850, 24612,  9286, 17784,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314,   301, 14879, 14664, 19783,   313,\n","         15868, 21579, 21235,  1700, 29809, 24536, 25614, 26605,   301, 20348,\n","         24536, 25614, 26545, 19512,     3,     3,     3,     3,     3,     3,\n","             3,     3],\n","        [    2,   315,   313, 15195,   314, 17254, 27818, 17254, 27818, 24536,\n","         25614, 26545, 19512, 15585,  1700,     3,     3,     3,     3,     3,\n","             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n","             3,     3]])\n","gensentences {'trans function function and restural', 'transual function functions요.', '같이 으럼 먹어보면 어떨까요?', '그래요 먼저 자시고 그러세요', 'transfer Contris for the end and raceful and restur'}\n","prob_label_is_true :  tensor([0.4666], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.1919], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.3952], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.2091], grad_fn=<SelectBackward>)\n","prob_label_is_true :  tensor([0.3632], grad_fn=<SelectBackward>)\n","{}\n","ranked []\n","----------------------------------------------------------------------------------------------------\n","[Casual]  Jimmy is on crack and can't trust him\n","----------------------------------------------------------------------------------------------------\n","No good quality transfers available !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2VXjU_tNhCCz"},"source":[""],"execution_count":null,"outputs":[]}]}